{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ea9f213-57ab-4dd6-b701-64c440041f29",
   "metadata": {},
   "source": [
    "Ref: Machine Learning Notebooks, 3rd edition https://github.com/ageron/handson-ml3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3456fe2c-5d23-4e39-bcdb-33640d003d2c",
   "metadata": {},
   "source": [
    "- Observation #1 -- The distribution was not normal, so we applied a log transform and that increased our accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98146963-2d40-4f54-8529-673bfce28813",
   "metadata": {},
   "source": [
    "- Artist\n",
    "- Album\n",
    "- Track -- this table might have all the features/attributes\n",
    "\n",
    "- Insight #1 -- X is correlated with Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa71d00f-f5e8-4bbe-b52b-4e4fe3485f4f",
   "metadata": {},
   "source": [
    "# Deliverables\n",
    "1. Presentation (Notebook)\n",
    "2. DagHub repo link\n",
    "3. Docker repo link\n",
    "4. Github repo link\n",
    "5. API Link\n",
    "6. Streamlit link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b86cbea-f4e0-4db8-8aa7-9b5d829f8cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "housing = pd.read_csv(\"housing.csv\")\n",
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "train, test = train_test_split(housing, test_size=0.2, stratify=housing[\"income_cat\"], random_state=42)\n",
    "train.drop(\"income_cat\", axis=1, inplace=True)\n",
    "test.drop(\"income_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f782131-f005-4360-bc60-223d944be4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class Preprocessor(BaseEstimator, TransformerMixin):\n",
    "    # Train our custom preprocessors\n",
    "    numerical_columns = [\n",
    "        'longitude',\n",
    "        'latitude',\n",
    "        'housing_median_age',\n",
    "        'total_rooms',\n",
    "        'total_bedrooms',\n",
    "        'population',\n",
    "        'households',\n",
    "        'median_income',\n",
    "    ]\n",
    "    categorical_columns = [\n",
    "        'ocean_proximity'\n",
    "    ]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        # Create and fit simple imputer\n",
    "        self.imputer = SimpleImputer(strategy='median')\n",
    "        self.imputer.fit(X[self.numerical_columns])\n",
    "\n",
    "        # Create and fit Standard Scaler\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(X[self.numerical_columns])\n",
    "\n",
    "        # Create and fit one hot encoder\n",
    "        self.onehot = OneHotEncoder(handle_unknown='ignore')\n",
    "        self.onehot.fit(X[self.categorical_columns])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "\n",
    "        # Apply simple imputer\n",
    "        imputed_cols = self.imputer.transform(X[self.numerical_columns])\n",
    "        onehot_cols = self.onehot.transform(X[self.categorical_columns])\n",
    "\n",
    "        # Copy the df\n",
    "        transformed_df = X.copy()\n",
    "\n",
    "        # Apply transformed columns\n",
    "        transformed_df[self.numerical_columns] = imputed_cols\n",
    "        transformed_df[self.numerical_columns] = self.scaler.transform(transformed_df[self.numerical_columns])\n",
    "\n",
    "        # Drop existing categorical columns and replace with one hot equivalent\n",
    "        transformed_df = transformed_df.drop(self.categorical_columns, axis=1)\n",
    "        transformed_df[self.onehot.get_feature_names_out()] = onehot_cols.toarray().astype(int)\n",
    "\n",
    "        return transformed_df\n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "y_train = train['median_house_value']\n",
    "X_train = train.drop('median_house_value', axis=1)\n",
    "\n",
    "y_test = test['median_house_value']\n",
    "X_test = test.drop('median_house_value', axis=1)\n",
    "\n",
    "rfg = make_pipeline(Preprocessor(), RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e7c1be3-1c92-4182-bfa2-cb295a118e36",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rgf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m rfg\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m----> 2\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m \u001b[43mrgf\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rgf' is not defined"
     ]
    }
   ],
   "source": [
    "rfg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ac3e3be-c29a-4785-9087-564b9b358246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"longitude\": -118.39,\n",
      "  \"latitude\": 34.12,\n",
      "  \"housing_median_age\": 29.0,\n",
      "  \"total_rooms\": 6447.0,\n",
      "  \"total_bedrooms\": 1012.0,\n",
      "  \"population\": 2184.0,\n",
      "  \"households\": 960.0,\n",
      "  \"median_income\": 8.2816,\n",
      "  \"ocean_proximity\": \"<1H OCEAN\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(X_test.iloc[0].to_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c11f5d0-3a6d-49dd-ab34-60a847868383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11856.918169815892"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "y_pred_train = rfg.predict(X_train)\n",
    "mean_absolute_error(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea91ef99-1dc5-4a2c-8ad0-c5f459ed93cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30883.678573158915"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = rfg.predict(X_test)\n",
    "mean_absolute_error(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9dbcb8d-6a42-40ba-a3ce-36a652b25594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dill import dump, load\n",
    "\n",
    "with open('rfg_model.pkl', 'wb') as f:\n",
    "    dump(rfg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fd27756-677d-47be-a172-f32b6f498ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rfg_model.pkl', 'rb') as f:\n",
    "    reloaded_model = load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d9a851c-35c6-40cf-b152-b5869da307f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30883.678573158915"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = reloaded_model.predict(X_test)\n",
    "mean_absolute_error(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa973285-b8f8-4853-90bf-6fd6663176af",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "  \"longitude\": -118.39,\n",
    "  \"latitude\": 34.12,\n",
    "  \"housing_median_age\": 29.0,\n",
    "  \"total_rooms\": 6447.0,\n",
    "  \"total_bedrooms\": 1012.0,\n",
    "  \"population\": 2184.0,\n",
    "  \"households\": 960.0,\n",
    "  \"median_income\": 8.2816,\n",
    "  \"ocean_proximity\": \"<1H OCEAN\"\n",
    "}\n",
    "\n",
    "df = pd.DataFrame([payload.values()], columns=payload.keys())\n",
    "df\n",
    "a = reloaded_model.predict(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "faaf990a-5271-4701-979f-f315ca96ec44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
